# general
run_name: 'rnn_meta_training_120_2_channel1' # training_200_2_channel1

# coding parameters
use_ecc: True # True, False
n_symbols: 32

# channel
memory_length: 4
channel_type: 'ISI_AWGN' # 'ISI_AWGN','Poisson'
channel_coefficients: 'time_decay' # 'time_decay','cost2100'
noisy_est_var: 0 # 0, 0.1 for ISI_AWGN, 0.08 for Poisson
fading_in_channel: True # True, False
fading_in_decoder: True # True, False
fading_taps_type: 1 # 1,2 or 3
subframes_in_frame: 25

# gamma values
gamma_start: 0.2
gamma_end: 0.2
gamma_num: 1

# validation hyperparameters
val_block_length: 1784
val_frames: 5
val_SNR_start: 12
val_SNR_end: 12
val_SNR_step: 1
eval_mode: 'aggregated' # 'aggregated','by_word'

# train hyperparameters
train_block_length: 120
train_frames: 12
train_minibatch_num: 25
train_minibatch_size: 32
train_SNR_start: 11
train_SNR_end: 11
train_SNR_step: 1
lr: 0.001 # learning rate
loss_type: 'CrossEntropy' # 'BCE','CrossEntropy','MSE'
print_every_n_train_minibatches: 1
optimizer_type: 'Adam' # 'Adam','RMSprop','SGD'

# seed
noise_seed: 3450002
word_seed: 7860002

# self-supervised online training
self_supervised: False # True, False
self_supervised_iterations: 200
ser_thresh: 0.02

# meta-learning
online_meta: False # False, True
meta_lr: 0.1
MAML: True # False, True
weights_init: 'last_frame' # 'random','last_frame','meta_training'
window_size: 1
buffer_empty: True
meta_train_iterations: 20
meta_j_num: 10
meta_subframes: 5