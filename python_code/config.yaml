# general
run_name: 'rnn_meta_training_200'

# coding parameters
use_ecc: False # True, False
n_symbols: 4

# channel
memory_length: 4
channel_type: 'ISI_AWGN' #'ISI_AWGN','Poisson'
noisy_est_var: 0 # 0, 0.1 for ISI_AWGN, 0.08 for Poisson
fading_in_channel: True # True, False
fading_in_decoder: True # True, False

# gamma values
gamma_start: 0.2
gamma_end: 0.2
gamma_num: 1

# validation hyperparameters
val_block_length: 200
val_words: 200
val_SNR_start: 12
val_SNR_end: 12
val_SNR_step: 2
eval_mode: 'aggregated' # 'aggregated','by_word'

# train hyperparameters
train_block_length: 200
train_words: 200
train_minibatch_num: 50
train_minibatch_size: 32
train_SNR_start: 12
train_SNR_end: 12
train_SNR_step: 2
lr: 0.001 # learning rate
loss_type: 'CrossEntropy' # 'BCE','CrossEntropy','MSE'
print_every_n_train_minibatches: 5
optimizer_type: 'Adam' # 'Adam','RMSprop','SGD'

# seed
noise_seed: 3450002
word_seed: 7860002

# self-supervised online training
self_supervised: False # True, False
self_supervised_iterations: 500
ser_thresh: 0.02
