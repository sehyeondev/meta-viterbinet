# general
run_name: 'meta_training'

# coding parameters
channel_blocks: 1
use_ecc: False
n_symbols: 8

# channel
memory_length: 4
channel_type: 'ISI_AWGN' #'ISI_AWGN','Poisson'
noisy_est_var: 0 # 0, 0.1 for ISI_AWGN, 0.08 for Poisson
fading_in_channel: True
fading_in_decoder: True

# gamma values
gamma_start: 0.2
gamma_end: 0.2
gamma_num: 1

# validation hyperparameters
val_block_length: 120
val_SNR_start: 10
val_SNR_end: 10
val_SNR_step: 2
val_words: 200
eval_mode: 'aggregated' # 'aggregated','by_word'

# train hyperparameters
train_block_length: 1000
train_minibatch_num: 5
train_minibatch_size: 100
train_SNR_start: 10
train_SNR_end: 10
train_SNR_step: 2
lr: 0.001 # learning rate
loss_type: 'CrossEntropy' # 'BCE','CrossEntropy','MSE'
print_every_n_train_minibatches: 10
optimizer_type: 'Adam' # 'Adam','RMSprop','SGD'
early_stopping_mode: False # True, False
self_supervised: True

# seed
noise_seed: 3450002
word_seed: 7860002

# meta
meta_words: 500
meta_lr: 0.001
support_size: 120