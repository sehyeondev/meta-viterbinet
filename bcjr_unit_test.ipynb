{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([0.5766]) tensor([0.3989])\n",
      "tensor([1.]) tensor([0.0680]) tensor([0.0540])\n",
      "tensor([0.]) tensor([0.3497]) tensor([0.2420])\n",
      "tensor([0.]) tensor([0.0056]) tensor([0.0044])\n",
      "tensor([0.]) tensor([0.5766]) tensor([0.3989])\n",
      "tensor([0.]) tensor([0.0680]) tensor([0.0540])\n",
      "tensor([0.]) tensor([0.3497]) tensor([0.2420])\n",
      "tensor([0.]) tensor([0.0056]) tensor([0.0044])\n",
      "tensor([0.8808]) tensor([0.0366]) tensor([0.0540])\n",
      "tensor([0.8808]) tensor([0.4977]) tensor([0.3989])\n",
      "tensor([0.1192]) tensor([0.1639]) tensor([0.2420])\n",
      "tensor([0.1192]) tensor([0.3018]) tensor([0.2420])\n",
      "tensor([0.]) tensor([0.0366]) tensor([0.0540])\n",
      "tensor([0.]) tensor([0.4977]) tensor([0.3989])\n",
      "tensor([0.]) tensor([0.1639]) tensor([0.2420])\n",
      "tensor([0.]) tensor([0.3018]) tensor([0.2420])\n",
      "tensor([0.1041]) tensor([0.0064]) tensor([0.0044])\n",
      "tensor([0.1041]) tensor([0.3455]) tensor([0.2420])\n",
      "tensor([0.7695]) tensor([0.0784]) tensor([0.0540])\n",
      "tensor([0.7695]) tensor([0.5697]) tensor([0.3989])\n",
      "tensor([0.0632]) tensor([0.0064]) tensor([0.0044])\n",
      "tensor([0.0632]) tensor([0.3455]) tensor([0.2420])\n",
      "tensor([0.0632]) tensor([0.0784]) tensor([0.0540])\n",
      "tensor([0.0632]) tensor([0.5697]) tensor([0.3989])\n",
      "tensor([0.0018]) tensor([0.2689]) tensor([0.2420])\n",
      "tensor([0.0018]) tensor([0.2353]) tensor([0.2420])\n",
      "tensor([0.0968]) tensor([0.4433]) tensor([0.3989])\n",
      "tensor([0.0968]) tensor([0.0525]) tensor([0.0540])\n",
      "tensor([0.1075]) tensor([0.2689]) tensor([0.2420])\n",
      "tensor([0.1075]) tensor([0.2353]) tensor([0.2420])\n",
      "tensor([0.7940]) tensor([0.4433]) tensor([0.3989])\n",
      "tensor([0.7940]) tensor([0.0525]) tensor([0.0540])\n",
      "tensor([0.0579]) tensor([0.0370]) tensor([0.0540])\n",
      "tensor([0.0579]) tensor([0.4963]) tensor([0.3989])\n",
      "tensor([0.0579]) tensor([0.1657]) tensor([0.2420])\n",
      "tensor([0.0579]) tensor([0.3010]) tensor([0.2420])\n",
      "tensor([0.7788]) tensor([0.0370]) tensor([0.0540])\n",
      "tensor([0.7788]) tensor([0.4963]) tensor([0.3989])\n",
      "tensor([0.1054]) tensor([0.1657]) tensor([0.2420])\n",
      "tensor([0.1054]) tensor([0.3010]) tensor([0.2420])\n",
      "tensor([0.0986]) tensor([0.0057]) tensor([0.0044])\n",
      "tensor([0.0986]) tensor([0.3494]) tensor([0.2420])\n",
      "tensor([0.7288]) tensor([0.0689]) tensor([0.0540])\n",
      "tensor([0.7288]) tensor([0.5761]) tensor([0.3989])\n",
      "tensor([0.0863]) tensor([0.0057]) tensor([0.0044])\n",
      "tensor([0.0863]) tensor([0.3494]) tensor([0.2420])\n",
      "tensor([0.0863]) tensor([0.0689]) tensor([0.0540])\n",
      "tensor([0.0863]) tensor([0.5761]) tensor([0.3989])\n",
      "tensor([0.0020]) tensor([0.2990]) tensor([0.2420])\n",
      "tensor([0.0020]) tensor([0.1702]) tensor([0.2420])\n",
      "tensor([0.1079]) tensor([0.4929]) tensor([0.3989])\n",
      "tensor([0.1079]) tensor([0.0380]) tensor([0.0540])\n",
      "tensor([0.1061]) tensor([0.2990]) tensor([0.2420])\n",
      "tensor([0.1061]) tensor([0.1702]) tensor([0.2420])\n",
      "tensor([0.7840]) tensor([0.4929]) tensor([0.3989])\n",
      "tensor([0.7840]) tensor([0.0380]) tensor([0.0540])\n",
      "tensor([0.0573]) tensor([0.5919]) tensor([0.3989])\n",
      "tensor([0.0573]) tensor([0.0454]) tensor([0.0540])\n",
      "tensor([0.0573]) tensor([0.3590]) tensor([0.2420])\n",
      "tensor([0.0573]) tensor([0.0037]) tensor([0.0044])\n",
      "tensor([0.7798]) tensor([0.5919]) tensor([0.3989])\n",
      "tensor([0.7798]) tensor([0.0454]) tensor([0.0540])\n",
      "tensor([0.1055]) tensor([0.3590]) tensor([0.2420])\n",
      "tensor([0.1055]) tensor([0.0037]) tensor([0.0044])\n",
      "tensor([0.7965]) tensor([0.5898]) tensor([0.3989])\n",
      "tensor([0.7965]) tensor([0.0484]) tensor([0.0540])\n",
      "tensor([0.1078]) tensor([0.3578]) tensor([0.2420])\n",
      "tensor([0.1078]) tensor([0.0040]) tensor([0.0044])\n",
      "tensor([0.0940]) tensor([0.5898]) tensor([0.3989])\n",
      "tensor([0.0940]) tensor([0.0484]) tensor([0.0540])\n",
      "tensor([0.0017]) tensor([0.3578]) tensor([0.2420])\n",
      "tensor([0.0017]) tensor([0.0040]) tensor([0.0044])\n",
      "tensor([0.8256]) tensor([0.6225]) tensor([0.3989])\n",
      "tensor([0.8256]) tensor([0.]) tensor([0.0540])\n",
      "tensor([0.1117]) tensor([0.3775]) tensor([0.2420])\n",
      "tensor([0.1117]) tensor([0.]) tensor([0.0044])\n",
      "tensor([0.0616]) tensor([0.6225]) tensor([0.3989])\n",
      "tensor([0.0616]) tensor([0.]) tensor([0.0540])\n",
      "tensor([0.0011]) tensor([0.3775]) tensor([0.2420])\n",
      "tensor([0.0011]) tensor([0.]) tensor([0.0044])\n"
     ]
    }
   ],
   "source": [
    "from python_code.channel.modulator import BPSKModulator\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def create_transition_table(n_states: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    creates transition table of size [n_states,2]\n",
    "    previous state of state i and input bit b is the state in cell [i,b]\n",
    "    \"\"\"\n",
    "    transition_table = np.concatenate([np.arange(n_states), np.arange(n_states)]).reshape(n_states, 2)\n",
    "    return transition_table\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "block_length = 10\n",
    "memory_length = 2\n",
    "n_states = 2 ** memory_length\n",
    "transmission_length = block_length\n",
    "batch_size = 1\n",
    "\n",
    "h = np.array([[1.0, 0.5]])  # Example channel coefficients\n",
    "x = torch.zeros(batch_size, block_length)\n",
    "y = torch.zeros(batch_size, transmission_length)\n",
    "\n",
    "c = np.array([1,1,2,2,1,2,2,1,1,1]).reshape(batch_size,block_length)-1\n",
    "padded_c = np.concatenate([c, np.zeros([c.shape[0], memory_length])], axis=1)\n",
    "s = 1 - 2 * padded_c\n",
    "blockwise_s = np.concatenate([s[:, i:-memory_length + i] for i in range(memory_length)], axis=0)\n",
    "conv = np.dot(h[:, ::-1], blockwise_s)\n",
    "[row, col] = conv.shape\n",
    "y[0, :] = torch.tensor(conv)\n",
    "\n",
    "\n",
    "transition_table_array = create_transition_table(n_states)\n",
    "transition_table = torch.Tensor(transition_table_array).to(device)\n",
    "\n",
    "snr = 0\n",
    "all_states_decimal = np.arange(n_states).astype(np.uint8).reshape(-1, 1)\n",
    "all_states_binary = np.unpackbits(all_states_decimal, axis=1).astype(int)\n",
    "all_states_symbols = BPSKModulator.modulate(all_states_binary[:, -memory_length:])\n",
    "state_priors = np.dot(all_states_symbols, h[:,::-1].T)\n",
    "state_priors = torch.Tensor(state_priors).to(device)\n",
    "\n",
    "priors = y.unsqueeze(dim=2) - state_priors.T.repeat(\n",
    "    repeats=[y.shape[0] // state_priors.shape[1], 1]).unsqueeze(\n",
    "    dim=1)\n",
    "# to llr representation\n",
    "sigma = 1 / 10 ** (-snr / 10)\n",
    "priors = priors ** 2 / (2 * sigma ** 2) + math.log(math.sqrt(2 * math.pi) * sigma)\n",
    "\n",
    "#### BCJR (sum product) ####\n",
    "# compute forward probabilities\n",
    "alpha = torch.zeros([y.shape[0], transmission_length+1, n_states]).to(device)\n",
    "alpha[:, 0, 0] = 1  # Initialization: start from state 0\n",
    "for i in range(1, transmission_length+1):\n",
    "    for state in range(n_states):\n",
    "        incoming_states = np.where(transition_table_array[:, 0] == state)[0].tolist() + \\\n",
    "                            np.where(transition_table_array[:, 1] == state)[0].tolist()\n",
    "        gamma = torch.exp(-priors[:, i - 1, state]).unsqueeze(dim=1)\n",
    "        alpha[:, i, state] = torch.sum(alpha[:, i - 1, incoming_states] * gamma, dim=1)\n",
    "    alpha[:, i, :] /= torch.sum(alpha[:, i, :], dim=1, keepdim=True)  # Normalize\n",
    "\n",
    "\n",
    "# compute backward probabilities\n",
    "beta = torch.zeros([y.shape[0], transmission_length+1, n_states]).to(device)\n",
    "beta[:, -1, 0] = 1  # Initialization: end state equally likely\n",
    "for i in range(transmission_length-1, -1, -1):\n",
    "    for state in range(n_states):\n",
    "        outgoing_states = transition_table_array[state]\n",
    "        gamma = torch.exp(-priors[:, i, state]).unsqueeze(dim=1)\n",
    "        beta[:, i, state] = torch.sum(beta[:, i + 1, outgoing_states] * gamma, dim=1)\n",
    "    beta[:, i, :] /= torch.sum(beta[:, i, :], dim=1, keepdim=True)  # Normalize\n",
    "\n",
    "# compute MAP v1\n",
    "decoded_word = torch.zeros([y.shape[0], transmission_length])\n",
    "for i in range(transmission_length):\n",
    "    up = torch.zeros(y.shape[0])\n",
    "    down = torch.zeros(y.shape[0])\n",
    "    for state in range(n_states):\n",
    "        for jj in range(2):\n",
    "            next_state = transition_table_array[state, jj]\n",
    "            _alpha = alpha[:, i, state]\n",
    "            _beta = beta[:, i, next_state]\n",
    "            _gamma = torch.exp(-priors[:, i, next_state])\n",
    "            print(_alpha, _beta, _gamma)\n",
    "            if jj == 0:\n",
    "                up += _alpha * _gamma * _beta\n",
    "            else:\n",
    "                down += _alpha * _gamma * _beta\n",
    "    decoded_word[:, i] = torch.where(up < down, 1, 0)\n",
    "\n",
    "prepend_word = torch.zeros([y.shape[0], memory_length-1]).to(device)\n",
    "decoded_word = torch.cat([prepend_word, decoded_word], dim=1)\n",
    "decoded_word = decoded_word[:,:transmission_length]\n",
    "\n",
    "ber = torch.sum(torch.abs(decoded_word - x)).item() / (batch_size * block_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viterbi_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
